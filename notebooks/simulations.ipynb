{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "current = os.getcwd()\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)\n",
    "\n",
    "from swp.utils.setup import seed_everything, set_device\n",
    "from swp.datasets.phonemes import get_phoneme_to_id\n",
    "\n",
    "seed_everything()\n",
    "device = set_device()\n",
    "phoneme_to_id = get_phoneme_to_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Word</th>\n",
       "      <th>Size</th>\n",
       "      <th>Length</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Zipf Frequency</th>\n",
       "      <th>Morphology</th>\n",
       "      <th>Lexicality</th>\n",
       "      <th>Part of Speech</th>\n",
       "      <th>Phonemes</th>\n",
       "      <th>...</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Edit Distance</th>\n",
       "      <th>Insertions</th>\n",
       "      <th>Deletions</th>\n",
       "      <th>Substitutions</th>\n",
       "      <th>Sequence Length</th>\n",
       "      <th>Error Indices</th>\n",
       "      <th>Bigram Frequency</th>\n",
       "      <th>Primacy Error</th>\n",
       "      <th>Recency Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>64</td>\n",
       "      <td>unkintep</td>\n",
       "      <td>long</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AH0', 'N', 'K', 'IH1', 'N', 'T', 'P', 'IH0',...</td>\n",
       "      <td>...</td>\n",
       "      <td>[AH, N, K, IH, N, T, IH, IH, NG]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[7]</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>170</td>\n",
       "      <td>woodority</td>\n",
       "      <td>long</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['W', 'UH1', 'D', 'ER0', 'AY2', 'IH0', 'T']</td>\n",
       "      <td>...</td>\n",
       "      <td>[W, UH, D, ER, AY, T, IH]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>75</td>\n",
       "      <td>predium</td>\n",
       "      <td>long</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['P', 'R', 'IY2', 'D', 'IY0', 'UW1', 'M', 'AH0']</td>\n",
       "      <td>...</td>\n",
       "      <td>[P, R, IY, D, IY, AH, M, AH]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>213</td>\n",
       "      <td>avalitect</td>\n",
       "      <td>long</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AE2', 'V', 'AH0', 'L', 'IH1', 'T', 'IH0', 'K...</td>\n",
       "      <td>...</td>\n",
       "      <td>[AE, V, AH, L, IH, T, IH, T, K]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[8, 9]</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>239</td>\n",
       "      <td>coallency</td>\n",
       "      <td>long</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['K', 'OW0', 'AA1', 'L', 'N', 'AH0', 'S', 'N',...</td>\n",
       "      <td>...</td>\n",
       "      <td>[K, OW, AA, L, S, AH, N, N, IY]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[5, 7]</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>84</td>\n",
       "      <td>qumb</td>\n",
       "      <td>short</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['K', 'M', 'AH1', 'B']</td>\n",
       "      <td>...</td>\n",
       "      <td>[K, L, AH, B]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>158</td>\n",
       "      <td>qusue</td>\n",
       "      <td>short</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simple</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['K', 'Y', 'UW1', 'S', 'UW0']</td>\n",
       "      <td>...</td>\n",
       "      <td>[K, Y, UW, R, UW]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>207</td>\n",
       "      <td>awarly</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AO1', 'ER0', 'AH0', 'L', 'IY0']</td>\n",
       "      <td>...</td>\n",
       "      <td>[AO, AH, AH, AH, IY]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       Word   Size  Length Frequency  Zipf Frequency  \\\n",
       "423           64   unkintep   long       8       NaN             NaN   \n",
       "529          170  woodority   long       9       NaN             NaN   \n",
       "653           75    predium   long       7       NaN             NaN   \n",
       "791          213  avalitect   long       9       NaN             NaN   \n",
       "817          239  coallency   long       9       NaN             NaN   \n",
       "1007          84       qumb  short       4       NaN             NaN   \n",
       "1081         158      qusue  short       5       NaN             NaN   \n",
       "1516         207     awarly  short       6       NaN             NaN   \n",
       "\n",
       "     Morphology Lexicality Part of Speech  \\\n",
       "423     complex     pseudo            NaN   \n",
       "529     complex     pseudo            NaN   \n",
       "653      simple     pseudo            NaN   \n",
       "791      simple     pseudo            NaN   \n",
       "817      simple     pseudo            NaN   \n",
       "1007     simple     pseudo            NaN   \n",
       "1081     simple     pseudo            NaN   \n",
       "1516    complex     pseudo            NaN   \n",
       "\n",
       "                                               Phonemes  ...  \\\n",
       "423   ['AH0', 'N', 'K', 'IH1', 'N', 'T', 'P', 'IH0',...  ...   \n",
       "529         ['W', 'UH1', 'D', 'ER0', 'AY2', 'IH0', 'T']  ...   \n",
       "653    ['P', 'R', 'IY2', 'D', 'IY0', 'UW1', 'M', 'AH0']  ...   \n",
       "791   ['AE2', 'V', 'AH0', 'L', 'IH1', 'T', 'IH0', 'K...  ...   \n",
       "817   ['K', 'OW0', 'AA1', 'L', 'N', 'AH0', 'S', 'N',...  ...   \n",
       "1007                             ['K', 'M', 'AH1', 'B']  ...   \n",
       "1081                      ['K', 'Y', 'UW1', 'S', 'UW0']  ...   \n",
       "1516                  ['AO1', 'ER0', 'AH0', 'L', 'IY0']  ...   \n",
       "\n",
       "                            Prediction Edit Distance  Insertions  Deletions  \\\n",
       "423   [AH, N, K, IH, N, T, IH, IH, NG]             1           0          0   \n",
       "529          [W, UH, D, ER, AY, T, IH]             2           1          1   \n",
       "653       [P, R, IY, D, IY, AH, M, AH]             1           0          0   \n",
       "791    [AE, V, AH, L, IH, T, IH, T, K]             2           1          1   \n",
       "817    [K, OW, AA, L, S, AH, N, N, IY]             2           0          0   \n",
       "1007                     [K, L, AH, B]             1           0          0   \n",
       "1081                 [K, Y, UW, R, UW]             1           0          0   \n",
       "1516              [AO, AH, AH, AH, IY]             2           0          0   \n",
       "\n",
       "      Substitutions  Sequence Length  Error Indices Bigram Frequency  \\\n",
       "423               1                9            [7]         0.009926   \n",
       "529               0                7         [6, 7]         0.002173   \n",
       "653               1                8            [6]         0.003280   \n",
       "791               0                9         [8, 9]         0.005405   \n",
       "817               2                9         [5, 7]         0.002247   \n",
       "1007              1                4            [2]         0.003126   \n",
       "1081              1                5            [4]         0.002362   \n",
       "1516              2                5         [2, 4]         0.005462   \n",
       "\n",
       "      Primacy Error  Recency Error  \n",
       "423               0              1  \n",
       "529               0              1  \n",
       "653               0              1  \n",
       "791               0              1  \n",
       "817               0              1  \n",
       "1007              1              0  \n",
       "1081              0              1  \n",
       "1516              1              1  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "from swp.utils.datasets import enrich_for_plotting, classify_error_positions\n",
    "\n",
    "test_df = pd.read_csv('../results/gridsearch/test/Ua_LSTM_h256_l1_v42_d0.5_t0.1_s1~b1024_l0.001_f0_sn/50.csv')\n",
    "test_df[\"No Stress\"] = test_df[\"No Stress\"].apply(literal_eval)\n",
    "test_df[\"Prediction\"] = test_df[\"Prediction\"].apply(literal_eval)\n",
    "test_df = enrich_for_plotting(test_df, include_stress=False)\n",
    "test_df = classify_error_positions(test_df)\n",
    "test_df[test_df[\"Edit Distance\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swp.utils.datasets import get_train_data, enrich_for_ablations\n",
    "\n",
    "train_data = get_train_data()\n",
    "\n",
    "# Sample the training data to get a smaller dataset\n",
    "train_data = train_data.sample(frac=0.1)\n",
    "train_data = enrich_for_ablations(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from swp.utils.paths import get_dataframe_dir\n",
    "\n",
    "# Save the dataframe\n",
    "dataframe_path = get_dataframe_dir() / 'ablation_train.csv'\n",
    "train_data.to_csv(dataframe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def cache_lstm_weights(layer):\n",
    "    \"\"\"Cache LSTM weights and biases for later restoration\"\"\"\n",
    "    weights = {\n",
    "        \"weight_ih_l0\": layer.weight_ih_l0.clone(),\n",
    "        \"weight_hh_l0\": layer.weight_hh_l0.clone(),\n",
    "        \"bias_ih_l0\": layer.bias_ih_l0.clone(),\n",
    "        \"bias_hh_l0\": layer.bias_hh_l0.clone(),\n",
    "    }\n",
    "    return weights\n",
    "\n",
    "\n",
    "def restore_lstm_weights(layer, weights):\n",
    "    \"\"\"Restore LSTM weights and biases from cache\"\"\"\n",
    "    with torch.no_grad():\n",
    "        layer.weight_ih_l0.copy_(weights[\"weight_ih_l0\"])\n",
    "        layer.weight_hh_l0.copy_(weights[\"weight_hh_l0\"])\n",
    "        layer.bias_ih_l0.copy_(weights[\"bias_ih_l0\"])\n",
    "        layer.bias_hh_l0.copy_(weights[\"bias_hh_l0\"])\n",
    "\n",
    "\n",
    "def ablate_lstm_neuron(layer, neuron_idx, num_neurons):\n",
    "    \"\"\"Zero out all four gates of a single LSTM neuron\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Compute row indices for all four gates\n",
    "        gate_indices = torch.tensor(\n",
    "            [\n",
    "                neuron_idx,\n",
    "                neuron_idx + num_neurons,\n",
    "                neuron_idx + num_neurons * 2,\n",
    "                neuron_idx + num_neurons * 3,\n",
    "            ]\n",
    "        )\n",
    "        # Zero out corresponding rows in weights and biases\n",
    "        layer.weight_ih_l0[gate_indices] = 0\n",
    "        layer.weight_hh_l0[gate_indices] = 0\n",
    "        layer.bias_ih_l0[gate_indices] = 0\n",
    "        layer.bias_hh_l0[gate_indices] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.embedding.weight torch.Size([42, 256])\n",
      "encoder.recurrent.weight_ih_l0 torch.Size([1024, 256])\n",
      "encoder.recurrent.weight_hh_l0 torch.Size([1024, 256])\n",
      "encoder.recurrent.bias_ih_l0 torch.Size([1024])\n",
      "encoder.recurrent.bias_hh_l0 torch.Size([1024])\n",
      "decoder.recurrent.weight_ih_l0 torch.Size([1024, 256])\n",
      "decoder.recurrent.weight_hh_l0 torch.Size([1024, 256])\n",
      "decoder.recurrent.bias_ih_l0 torch.Size([1024])\n",
      "decoder.recurrent.bias_hh_l0 torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "<generator object Module.named_parameters at 0x140808cf0>\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from swp.utils.models import get_model, load_weights\n",
    "\n",
    "model_name = \"Ua_LSTM_h256_l1_v42_d0.5_t0.1_s1\"\n",
    "train_name = \"b1024_l0.001_f0_sn\"\n",
    "\n",
    "model = get_model(model_name)\n",
    "load_weights(model, model_name, train_name, \"50\", device)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "\n",
    "print(model.encoder.recurrent.bias_ih_l0.shape)\n",
    "\n",
    "print(model.named_parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Word</th>\n",
       "      <th>Size</th>\n",
       "      <th>Length</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Zipf Frequency</th>\n",
       "      <th>Morphology</th>\n",
       "      <th>Lexicality</th>\n",
       "      <th>Part of Speech</th>\n",
       "      <th>Phonemes</th>\n",
       "      <th>No Stress</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Edit Distance</th>\n",
       "      <th>Insertions</th>\n",
       "      <th>Deletions</th>\n",
       "      <th>Substitutions</th>\n",
       "      <th>Sequence Length</th>\n",
       "      <th>Error Indices</th>\n",
       "      <th>Bigram Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bathmat</td>\n",
       "      <td>long</td>\n",
       "      <td>7</td>\n",
       "      <td>low</td>\n",
       "      <td>1.55</td>\n",
       "      <td>complex</td>\n",
       "      <td>real</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>['B', 'AE1', 'TH', 'M', 'AH0', 'T']</td>\n",
       "      <td>[B, AE, TH, M, AH, T]</td>\n",
       "      <td>[B, AE, TH, M, AH, T]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>decoder</td>\n",
       "      <td>long</td>\n",
       "      <td>7</td>\n",
       "      <td>low</td>\n",
       "      <td>2.84</td>\n",
       "      <td>complex</td>\n",
       "      <td>real</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>['D', 'IH0', 'K', 'OW1', 'D', 'ER0']</td>\n",
       "      <td>[D, IH, K, OW, D, ER]</td>\n",
       "      <td>[D, IH, K, OW, D, ER]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.002864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>defiant</td>\n",
       "      <td>long</td>\n",
       "      <td>7</td>\n",
       "      <td>low</td>\n",
       "      <td>3.21</td>\n",
       "      <td>complex</td>\n",
       "      <td>real</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>['D', 'IH0', 'F', 'AY1', 'AH0', 'N', 'T']</td>\n",
       "      <td>[D, IH, F, AY, AH, N, T]</td>\n",
       "      <td>[D, IH, F, AY, AH, N, T]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.009445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>padlock</td>\n",
       "      <td>long</td>\n",
       "      <td>7</td>\n",
       "      <td>low</td>\n",
       "      <td>2.68</td>\n",
       "      <td>complex</td>\n",
       "      <td>real</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>['P', 'AE1', 'D', 'L', 'AA2', 'K']</td>\n",
       "      <td>[P, AE, D, L, AA, K]</td>\n",
       "      <td>[P, AE, D, L, AA, K]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>immoral</td>\n",
       "      <td>long</td>\n",
       "      <td>7</td>\n",
       "      <td>low</td>\n",
       "      <td>3.46</td>\n",
       "      <td>complex</td>\n",
       "      <td>real</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>['IH0', 'M', 'AO1', 'R', 'AH0', 'L']</td>\n",
       "      <td>[IH, M, AO, R, AH, L]</td>\n",
       "      <td>[IH, M, AO, R, AH, L]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.007904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>340</td>\n",
       "      <td>unrich</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AH1', 'N', 'R', 'IH0', 'CH']</td>\n",
       "      <td>[AH, N, R, IH, CH]</td>\n",
       "      <td>[AH, N, R, IH, CH]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.010701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>341</td>\n",
       "      <td>upholt</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['AH0', 'P', 'OW1', 'L', 'T']</td>\n",
       "      <td>[AH, P, OW, L, T]</td>\n",
       "      <td>[AH, P, OW, L, T]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>342</td>\n",
       "      <td>warels</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['W', 'EH1', 'R', 'AH0', 'L', 'Z']</td>\n",
       "      <td>[W, EH, R, AH, L, Z]</td>\n",
       "      <td>[W, EH, R, AH, L, Z]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.006488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>343</td>\n",
       "      <td>wately</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['W', 'EY1', 'T', 'L', 'IY0']</td>\n",
       "      <td>[W, EY, T, L, IY]</td>\n",
       "      <td>[W, EY, T, L, IY]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.003228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>344</td>\n",
       "      <td>yeards</td>\n",
       "      <td>short</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>complex</td>\n",
       "      <td>pseudo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Y', 'IH1', 'R', 'D', 'Z']</td>\n",
       "      <td>[Y, IH, R, D, Z]</td>\n",
       "      <td>[Y, IH, R, D, Z]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1654 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     Word   Size  Length Frequency  Zipf Frequency Morphology  \\\n",
       "0              0  bathmat   long       7       low            1.55    complex   \n",
       "1              1  decoder   long       7       low            2.84    complex   \n",
       "2              2  defiant   long       7       low            3.21    complex   \n",
       "3              3  padlock   long       7       low            2.68    complex   \n",
       "4              4  immoral   long       7       low            3.46    complex   \n",
       "...          ...      ...    ...     ...       ...             ...        ...   \n",
       "1649         340   unrich  short       6       NaN             NaN    complex   \n",
       "1650         341   upholt  short       6       NaN             NaN    complex   \n",
       "1651         342   warels  short       6       NaN             NaN    complex   \n",
       "1652         343   wately  short       6       NaN             NaN    complex   \n",
       "1653         344   yeards  short       6       NaN             NaN    complex   \n",
       "\n",
       "     Lexicality Part of Speech                                   Phonemes  \\\n",
       "0          real           NOUN        ['B', 'AE1', 'TH', 'M', 'AH0', 'T']   \n",
       "1          real           NOUN       ['D', 'IH0', 'K', 'OW1', 'D', 'ER0']   \n",
       "2          real            ADJ  ['D', 'IH0', 'F', 'AY1', 'AH0', 'N', 'T']   \n",
       "3          real           NOUN         ['P', 'AE1', 'D', 'L', 'AA2', 'K']   \n",
       "4          real            ADJ       ['IH0', 'M', 'AO1', 'R', 'AH0', 'L']   \n",
       "...         ...            ...                                        ...   \n",
       "1649     pseudo            NaN             ['AH1', 'N', 'R', 'IH0', 'CH']   \n",
       "1650     pseudo            NaN              ['AH0', 'P', 'OW1', 'L', 'T']   \n",
       "1651     pseudo            NaN         ['W', 'EH1', 'R', 'AH0', 'L', 'Z']   \n",
       "1652     pseudo            NaN              ['W', 'EY1', 'T', 'L', 'IY0']   \n",
       "1653     pseudo            NaN                ['Y', 'IH1', 'R', 'D', 'Z']   \n",
       "\n",
       "                     No Stress                Prediction  Edit Distance  \\\n",
       "0        [B, AE, TH, M, AH, T]     [B, AE, TH, M, AH, T]              0   \n",
       "1        [D, IH, K, OW, D, ER]     [D, IH, K, OW, D, ER]              0   \n",
       "2     [D, IH, F, AY, AH, N, T]  [D, IH, F, AY, AH, N, T]              0   \n",
       "3         [P, AE, D, L, AA, K]      [P, AE, D, L, AA, K]              0   \n",
       "4        [IH, M, AO, R, AH, L]     [IH, M, AO, R, AH, L]              0   \n",
       "...                        ...                       ...            ...   \n",
       "1649        [AH, N, R, IH, CH]        [AH, N, R, IH, CH]              0   \n",
       "1650         [AH, P, OW, L, T]         [AH, P, OW, L, T]              0   \n",
       "1651      [W, EH, R, AH, L, Z]      [W, EH, R, AH, L, Z]              0   \n",
       "1652         [W, EY, T, L, IY]         [W, EY, T, L, IY]              0   \n",
       "1653          [Y, IH, R, D, Z]          [Y, IH, R, D, Z]              0   \n",
       "\n",
       "      Insertions  Deletions  Substitutions  Sequence Length Error Indices  \\\n",
       "0              0          0              0                6            []   \n",
       "1              0          0              0                6            []   \n",
       "2              0          0              0                7            []   \n",
       "3              0          0              0                6            []   \n",
       "4              0          0              0                6            []   \n",
       "...          ...        ...            ...              ...           ...   \n",
       "1649           0          0              0                5            []   \n",
       "1650           0          0              0                5            []   \n",
       "1651           0          0              0                6            []   \n",
       "1652           0          0              0                5            []   \n",
       "1653           0          0              0                5            []   \n",
       "\n",
       "      Bigram Frequency  \n",
       "0             0.003116  \n",
       "1             0.002864  \n",
       "2             0.009445  \n",
       "3             0.000953  \n",
       "4             0.007904  \n",
       "...                ...  \n",
       "1649          0.010701  \n",
       "1650          0.001672  \n",
       "1651          0.006488  \n",
       "1652          0.003228  \n",
       "1653          0.001656  \n",
       "\n",
       "[1654 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from swp.utils.datasets import get_train_data, get_phoneme_statistics\n",
    "from swp.utils.plots import enrich_for_plotting\n",
    "from ast import literal_eval\n",
    "\n",
    "# train_df = get_train_data()\n",
    "# phoneme_statistics = get_phoneme_statistics(train_df)\n",
    "\n",
    "test_df = pd.read_csv('../results/gridsearch/test/Ua_LSTM_h256_l1_v42_d0.5_t0.1_s1~b1024_l0.001_f0_sn/50.csv')\n",
    "test_df[\"No Stress\"] = test_df[\"No Stress\"].apply(literal_eval)\n",
    "test_df[\"Prediction\"] = test_df[\"Prediction\"].apply(literal_eval)\n",
    "\n",
    "df = enrich_for_plotting(test_df, phoneme_to_id, False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([3, 4])\n",
      "Per-sequence errors: tensor([False,  True, False])\n",
      "Number of sequences with errors: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example preds and target tensors\n",
    "preds = torch.tensor([[1, 0, 2, 0],   # Matches\n",
    "                      [0, 1, 1, 1],   # One mismatch\n",
    "                      [2, 2, 0, 0]])  # Mismatches but padded at the end\n",
    "target = torch.tensor([[1, 0, 2, -100],  # Matches (ignore -100)\n",
    "                       [0, 1, 0, -100],  # Mismatch at position 2\n",
    "                       [2, 2, -100, -100]])  # All mismatches are ignored\n",
    "\n",
    "# Mask for valid positions\n",
    "mask = target != -100\n",
    "\n",
    "print(preds.shape, target.shape)\n",
    "\n",
    "# Element-wise comparison\n",
    "comparison = (preds != target) & mask\n",
    "\n",
    "# Check per sequence if there's any mismatch\n",
    "per_sequence_error = torch.any(comparison, dim=1)\n",
    "\n",
    "# Count the number of sequences with errors\n",
    "num_errors = per_sequence_error.sum().item()\n",
    "\n",
    "print(f\"Per-sequence errors: {per_sequence_error}\")  # tensor([False,  True, False])\n",
    "print(f\"Number of sequences with errors: {num_errors}\")  # Output: 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swpm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
